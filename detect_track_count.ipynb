{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952447c5-2882-4096-9fb3-3f61099349fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.2.60)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.18.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manasa\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200a53af-ba38-4a44-9245-0f8c1ce871db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.2.60'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c260943-b848-4670-bc48-5601b74ab0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import*\n",
    "\n",
    "model=YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e982ba-73a7-49d1-93eb-bb69723a692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e629ccb1-8ddf-4a16-a604-6606f9f4c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=Tracker()\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d0e991-23f5-4eee-93da-9486c77a4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture('highway.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a76103-221f-40ae-9365-dabbff2f0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "down={}\n",
    "up={}\n",
    "\n",
    "counter_down=[]\n",
    "counter_up=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3658831-aaea-40b9-96f4-0dad7be11d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 8 cars, 2 trucks, 883.8ms\n",
      "Speed: 0.0ms preprocess, 883.8ms inference, 6.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 893.5ms\n",
      "Speed: 2.8ms preprocess, 893.5ms inference, 16.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 910.2ms\n",
      "Speed: 0.0ms preprocess, 910.2ms inference, 7.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 2 trucks, 953.8ms\n",
      "Speed: 9.1ms preprocess, 953.8ms inference, 16.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 946.0ms\n",
      "Speed: 10.8ms preprocess, 946.0ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 863.1ms\n",
      "Speed: 4.9ms preprocess, 863.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 881.9ms\n",
      "Speed: 4.8ms preprocess, 881.9ms inference, 14.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 913.8ms\n",
      "Speed: 5.0ms preprocess, 913.8ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 968.9ms\n",
      "Speed: 11.5ms preprocess, 968.9ms inference, 6.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 899.3ms\n",
      "Speed: 4.0ms preprocess, 899.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 898.5ms\n",
      "Speed: 0.0ms preprocess, 898.5ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 882.9ms\n",
      "Speed: 14.8ms preprocess, 882.9ms inference, 17.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 965.1ms\n",
      "Speed: 8.0ms preprocess, 965.1ms inference, 11.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 1005.3ms\n",
      "Speed: 5.8ms preprocess, 1005.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 978.5ms\n",
      "Speed: 8.5ms preprocess, 978.5ms inference, 14.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 348.4ms\n",
      "Speed: 0.0ms preprocess, 348.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 350.3ms\n",
      "Speed: 2.5ms preprocess, 350.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 398.3ms\n",
      "Speed: 0.0ms preprocess, 398.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 1 truck, 386.4ms\n",
      "Speed: 5.9ms preprocess, 386.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 414.3ms\n",
      "Speed: 6.3ms preprocess, 414.3ms inference, 11.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 494.2ms\n",
      "Speed: 0.0ms preprocess, 494.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 375.3ms\n",
      "Speed: 5.7ms preprocess, 375.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 449.8ms\n",
      "Speed: 0.0ms preprocess, 449.8ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 409.8ms\n",
      "Speed: 0.0ms preprocess, 409.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 350.8ms\n",
      "Speed: 2.7ms preprocess, 350.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 400.1ms\n",
      "Speed: 3.4ms preprocess, 400.1ms inference, 6.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 346.6ms\n",
      "Speed: 1.8ms preprocess, 346.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 341.4ms\n",
      "Speed: 12.5ms preprocess, 341.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 392.5ms\n",
      "Speed: 0.0ms preprocess, 392.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 387.8ms\n",
      "Speed: 8.0ms preprocess, 387.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 369.5ms\n",
      "Speed: 5.6ms preprocess, 369.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 324.9ms\n",
      "Speed: 0.0ms preprocess, 324.9ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 1 truck, 400.2ms\n",
      "Speed: 2.0ms preprocess, 400.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 336.7ms\n",
      "Speed: 0.0ms preprocess, 336.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 357.2ms\n",
      "Speed: 6.7ms preprocess, 357.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 361.4ms\n",
      "Speed: 0.0ms preprocess, 361.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 322.3ms\n",
      "Speed: 0.0ms preprocess, 322.3ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 381.5ms\n",
      "Speed: 0.0ms preprocess, 381.5ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 360.6ms\n",
      "Speed: 4.1ms preprocess, 360.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 399.2ms\n",
      "Speed: 0.0ms preprocess, 399.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 369.0ms\n",
      "Speed: 13.0ms preprocess, 369.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 374.0ms\n",
      "Speed: 3.6ms preprocess, 374.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 339.2ms\n",
      "Speed: 0.0ms preprocess, 339.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 441.4ms\n",
      "Speed: 0.0ms preprocess, 441.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 377.8ms\n",
      "Speed: 5.4ms preprocess, 377.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 348.2ms\n",
      "Speed: 0.0ms preprocess, 348.2ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 432.4ms\n",
      "Speed: 4.0ms preprocess, 432.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 361.5ms\n",
      "Speed: 1.3ms preprocess, 361.5ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 354.1ms\n",
      "Speed: 8.3ms preprocess, 354.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 1 bench, 405.0ms\n",
      "Speed: 7.5ms preprocess, 405.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 1 truck, 1 bench, 386.9ms\n",
      "Speed: 1.7ms preprocess, 386.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 1 bench, 416.5ms\n",
      "Speed: 8.1ms preprocess, 416.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 392.8ms\n",
      "Speed: 11.0ms preprocess, 392.8ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 1 bench, 313.3ms\n",
      "Speed: 3.0ms preprocess, 313.3ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 1 bench, 319.9ms\n",
      "Speed: 3.0ms preprocess, 319.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 1 bench, 359.8ms\n",
      "Speed: 0.0ms preprocess, 359.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 1 bench, 367.5ms\n",
      "Speed: 0.0ms preprocess, 367.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 419.5ms\n",
      "Speed: 0.0ms preprocess, 419.5ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 361.5ms\n",
      "Speed: 4.4ms preprocess, 361.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 412.4ms\n",
      "Speed: 5.5ms preprocess, 412.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 366.3ms\n",
      "Speed: 0.0ms preprocess, 366.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 382.0ms\n",
      "Speed: 0.0ms preprocess, 382.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 381.1ms\n",
      "Speed: 7.0ms preprocess, 381.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 371.2ms\n",
      "Speed: 9.5ms preprocess, 371.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 399.6ms\n",
      "Speed: 0.0ms preprocess, 399.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 1 bench, 387.8ms\n",
      "Speed: 15.8ms preprocess, 387.8ms inference, 6.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 1 bench, 350.4ms\n",
      "Speed: 1.8ms preprocess, 350.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 1 truck, 349.6ms\n",
      "Speed: 0.0ms preprocess, 349.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 1 truck, 383.4ms\n",
      "Speed: 10.8ms preprocess, 383.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 2 trucks, 342.8ms\n",
      "Speed: 10.4ms preprocess, 342.8ms inference, 9.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 381.6ms\n",
      "Speed: 3.9ms preprocess, 381.6ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 316.9ms\n",
      "Speed: 4.5ms preprocess, 316.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 338.6ms\n",
      "Speed: 1.6ms preprocess, 338.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 445.3ms\n",
      "Speed: 8.0ms preprocess, 445.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 377.2ms\n",
      "Speed: 4.9ms preprocess, 377.2ms inference, 12.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 372.4ms\n",
      "Speed: 8.2ms preprocess, 372.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 337.4ms\n",
      "Speed: 11.5ms preprocess, 337.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 384.8ms\n",
      "Speed: 15.0ms preprocess, 384.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 376.3ms\n",
      "Speed: 0.0ms preprocess, 376.3ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 1 truck, 365.1ms\n",
      "Speed: 0.0ms preprocess, 365.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 1 truck, 421.2ms\n",
      "Speed: 4.0ms preprocess, 421.2ms inference, 8.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 1 truck, 397.2ms\n",
      "Speed: 2.1ms preprocess, 397.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 2 trucks, 398.3ms\n",
      "Speed: 2.9ms preprocess, 398.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 2 trucks, 369.8ms\n",
      "Speed: 5.9ms preprocess, 369.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 324.4ms\n",
      "Speed: 13.1ms preprocess, 324.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 379.5ms\n",
      "Speed: 0.5ms preprocess, 379.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 300.3ms\n",
      "Speed: 8.1ms preprocess, 300.3ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 447.3ms\n",
      "Speed: 6.9ms preprocess, 447.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 2 trucks, 362.6ms\n",
      "Speed: 5.1ms preprocess, 362.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 2 trucks, 365.0ms\n",
      "Speed: 0.0ms preprocess, 365.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 2 trucks, 387.2ms\n",
      "Speed: 3.3ms preprocess, 387.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 333.3ms\n",
      "Speed: 12.0ms preprocess, 333.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 346.7ms\n",
      "Speed: 1.0ms preprocess, 346.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 3 trucks, 384.8ms\n",
      "Speed: 9.0ms preprocess, 384.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 338.8ms\n",
      "Speed: 5.0ms preprocess, 338.8ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 347.1ms\n",
      "Speed: 3.8ms preprocess, 347.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 329.3ms\n",
      "Speed: 2.0ms preprocess, 329.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 349.6ms\n",
      "Speed: 6.1ms preprocess, 349.6ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 4 trucks, 389.4ms\n",
      "Speed: 0.0ms preprocess, 389.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 5 trucks, 341.8ms\n",
      "Speed: 3.2ms preprocess, 341.8ms inference, 12.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 5 trucks, 359.4ms\n",
      "Speed: 4.4ms preprocess, 359.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 4 trucks, 360.7ms\n",
      "Speed: 0.0ms preprocess, 360.7ms inference, 13.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 trucks, 378.3ms\n",
      "Speed: 0.0ms preprocess, 378.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 5 trucks, 331.9ms\n",
      "Speed: 1.0ms preprocess, 331.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 3 trucks, 371.7ms\n",
      "Speed: 8.3ms preprocess, 371.7ms inference, 15.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 3 trucks, 373.0ms\n",
      "Speed: 4.9ms preprocess, 373.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 4 trucks, 372.0ms\n",
      "Speed: 3.0ms preprocess, 372.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 4 trucks, 400.6ms\n",
      "Speed: 4.6ms preprocess, 400.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 4 trucks, 376.3ms\n",
      "Speed: 6.5ms preprocess, 376.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 4 trucks, 362.8ms\n",
      "Speed: 0.0ms preprocess, 362.8ms inference, 16.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 4 trucks, 375.4ms\n",
      "Speed: 7.7ms preprocess, 375.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 3 trucks, 417.7ms\n",
      "Speed: 0.0ms preprocess, 417.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 trucks, 346.4ms\n",
      "Speed: 6.6ms preprocess, 346.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 trucks, 362.2ms\n",
      "Speed: 0.6ms preprocess, 362.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 3 trucks, 393.9ms\n",
      "Speed: 0.0ms preprocess, 393.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 3 trucks, 339.5ms\n",
      "Speed: 7.0ms preprocess, 339.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 trucks, 380.4ms\n",
      "Speed: 17.1ms preprocess, 380.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 3 trucks, 312.8ms\n",
      "Speed: 6.7ms preprocess, 312.8ms inference, 15.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 4 trucks, 320.9ms\n",
      "Speed: 9.6ms preprocess, 320.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 trucks, 369.5ms\n",
      "Speed: 0.0ms preprocess, 369.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 trucks, 356.0ms\n",
      "Speed: 5.0ms preprocess, 356.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 trucks, 331.7ms\n",
      "Speed: 5.0ms preprocess, 331.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 3 trucks, 362.6ms\n",
      "Speed: 10.9ms preprocess, 362.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 3 trucks, 355.4ms\n",
      "Speed: 0.0ms preprocess, 355.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 4 trucks, 385.2ms\n",
      "Speed: 0.0ms preprocess, 385.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 399.7ms\n",
      "Speed: 4.6ms preprocess, 399.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 4 trucks, 380.2ms\n",
      "Speed: 3.0ms preprocess, 380.2ms inference, 11.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 386.7ms\n",
      "Speed: 10.3ms preprocess, 386.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 360.7ms\n",
      "Speed: 0.0ms preprocess, 360.7ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 4 trucks, 425.7ms\n",
      "Speed: 8.0ms preprocess, 425.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 5 trucks, 361.9ms\n",
      "Speed: 0.0ms preprocess, 361.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 5 trucks, 330.6ms\n",
      "Speed: 3.7ms preprocess, 330.6ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 367.0ms\n",
      "Speed: 0.0ms preprocess, 367.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 4 trucks, 365.8ms\n",
      "Speed: 3.2ms preprocess, 365.8ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 3 trucks, 348.8ms\n",
      "Speed: 5.2ms preprocess, 348.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 378.8ms\n",
      "Speed: 4.1ms preprocess, 378.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 366.4ms\n",
      "Speed: 3.1ms preprocess, 366.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 383.6ms\n",
      "Speed: 0.0ms preprocess, 383.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 316.5ms\n",
      "Speed: 0.0ms preprocess, 316.5ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 401.3ms\n",
      "Speed: 5.1ms preprocess, 401.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 364.3ms\n",
      "Speed: 6.4ms preprocess, 364.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 342.1ms\n",
      "Speed: 0.8ms preprocess, 342.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 336.0ms\n",
      "Speed: 7.0ms preprocess, 336.0ms inference, 7.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 367.6ms\n",
      "Speed: 0.0ms preprocess, 367.6ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 363.3ms\n",
      "Speed: 7.3ms preprocess, 363.3ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 428.8ms\n",
      "Speed: 8.5ms preprocess, 428.8ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 3 trucks, 350.0ms\n",
      "Speed: 2.7ms preprocess, 350.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 347.7ms\n",
      "Speed: 5.5ms preprocess, 347.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 487.5ms\n",
      "Speed: 4.2ms preprocess, 487.5ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 3 trucks, 437.1ms\n",
      "Speed: 5.7ms preprocess, 437.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 3 trucks, 367.1ms\n",
      "Speed: 0.0ms preprocess, 367.1ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 3 trucks, 337.9ms\n",
      "Speed: 3.4ms preprocess, 337.9ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 3 trucks, 350.7ms\n",
      "Speed: 7.5ms preprocess, 350.7ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 13 cars, 3 trucks, 359.7ms\n",
      "Speed: 6.9ms preprocess, 359.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 3 trucks, 340.3ms\n",
      "Speed: 0.0ms preprocess, 340.3ms inference, 15.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 4 trucks, 314.1ms\n",
      "Speed: 3.4ms preprocess, 314.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 11 cars, 4 trucks, 330.7ms\n",
      "Speed: 0.0ms preprocess, 330.7ms inference, 0.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 12 cars, 4 trucks, 329.3ms\n",
      "Speed: 0.0ms preprocess, 329.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 6 trucks, 325.4ms\n",
      "Speed: 0.0ms preprocess, 325.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 5 trucks, 300.9ms\n",
      "Speed: 2.7ms preprocess, 300.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 312.1ms\n",
      "Speed: 16.8ms preprocess, 312.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 316.2ms\n",
      "Speed: 0.0ms preprocess, 316.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 325.3ms\n",
      "Speed: 1.1ms preprocess, 325.3ms inference, 15.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 315.6ms\n",
      "Speed: 0.0ms preprocess, 315.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 4 trucks, 320.1ms\n",
      "Speed: 0.0ms preprocess, 320.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 320.4ms\n",
      "Speed: 10.0ms preprocess, 320.4ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 6 trucks, 367.9ms\n",
      "Speed: 0.0ms preprocess, 367.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 6 trucks, 327.8ms\n",
      "Speed: 0.0ms preprocess, 327.8ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 342.8ms\n",
      "Speed: 3.4ms preprocess, 342.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 394.2ms\n",
      "Speed: 0.0ms preprocess, 394.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 6 trucks, 325.4ms\n",
      "Speed: 0.0ms preprocess, 325.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 5 trucks, 332.8ms\n",
      "Speed: 0.0ms preprocess, 332.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 5 trucks, 322.6ms\n",
      "Speed: 1.4ms preprocess, 322.6ms inference, 8.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 6 trucks, 303.4ms\n",
      "Speed: 5.5ms preprocess, 303.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 6 trucks, 304.0ms\n",
      "Speed: 1.1ms preprocess, 304.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 319.6ms\n",
      "Speed: 0.0ms preprocess, 319.6ms inference, 8.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 5 trucks, 345.0ms\n",
      "Speed: 0.0ms preprocess, 345.0ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 5 trucks, 313.5ms\n",
      "Speed: 3.5ms preprocess, 313.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 5 trucks, 318.1ms\n",
      "Speed: 6.9ms preprocess, 318.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 6 trucks, 308.4ms\n",
      "Speed: 14.8ms preprocess, 308.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 318.8ms\n",
      "Speed: 13.5ms preprocess, 318.8ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 6 trucks, 304.3ms\n",
      "Speed: 11.0ms preprocess, 304.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 6 trucks, 316.8ms\n",
      "Speed: 0.0ms preprocess, 316.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 7 trucks, 328.9ms\n",
      "Speed: 0.0ms preprocess, 328.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 6 trucks, 313.9ms\n",
      "Speed: 3.6ms preprocess, 313.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 4 trucks, 304.2ms\n",
      "Speed: 12.0ms preprocess, 304.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 5 trucks, 316.1ms\n",
      "Speed: 0.0ms preprocess, 316.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 7 trucks, 308.0ms\n",
      "Speed: 4.0ms preprocess, 308.0ms inference, 8.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 6 trucks, 353.3ms\n",
      "Speed: 1.0ms preprocess, 353.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 7 trucks, 376.8ms\n",
      "Speed: 0.0ms preprocess, 376.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 6 cars, 5 trucks, 336.4ms\n",
      "Speed: 5.0ms preprocess, 336.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 5 trucks, 380.4ms\n",
      "Speed: 6.1ms preprocess, 380.4ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 311.6ms\n",
      "Speed: 4.0ms preprocess, 311.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 5 trucks, 304.4ms\n",
      "Speed: 1.3ms preprocess, 304.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 312.7ms\n",
      "Speed: 0.0ms preprocess, 312.7ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 316.2ms\n",
      "Speed: 17.4ms preprocess, 316.2ms inference, 9.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 4 trucks, 369.4ms\n",
      "Speed: 3.4ms preprocess, 369.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 4 trucks, 299.8ms\n",
      "Speed: 3.1ms preprocess, 299.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 303.1ms\n",
      "Speed: 8.0ms preprocess, 303.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 4 trucks, 304.1ms\n",
      "Speed: 11.0ms preprocess, 304.1ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 299.3ms\n",
      "Speed: 1.2ms preprocess, 299.3ms inference, 12.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 301.2ms\n",
      "Speed: 3.6ms preprocess, 301.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 3 trucks, 326.6ms\n",
      "Speed: 0.0ms preprocess, 326.6ms inference, 11.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 317.8ms\n",
      "Speed: 5.1ms preprocess, 317.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 5 trucks, 316.4ms\n",
      "Speed: 0.0ms preprocess, 316.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 5 trucks, 309.8ms\n",
      "Speed: 11.0ms preprocess, 309.8ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 320.1ms\n",
      "Speed: 4.6ms preprocess, 320.1ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 trucks, 325.2ms\n",
      "Speed: 15.5ms preprocess, 325.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 300.0ms\n",
      "Speed: 16.0ms preprocess, 300.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 316.4ms\n",
      "Speed: 1.5ms preprocess, 316.4ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 325.1ms\n",
      "Speed: 4.5ms preprocess, 325.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 303.3ms\n",
      "Speed: 10.0ms preprocess, 303.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 332.2ms\n",
      "Speed: 0.0ms preprocess, 332.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 303.6ms\n",
      "Speed: 13.0ms preprocess, 303.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 312.3ms\n",
      "Speed: 0.0ms preprocess, 312.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 302.7ms\n",
      "Speed: 7.4ms preprocess, 302.7ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 371.0ms\n",
      "Speed: 1.6ms preprocess, 371.0ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 324.4ms\n",
      "Speed: 3.7ms preprocess, 324.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 325.3ms\n",
      "Speed: 4.5ms preprocess, 325.3ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 294.0ms\n",
      "Speed: 1.0ms preprocess, 294.0ms inference, 16.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 305.1ms\n",
      "Speed: 3.3ms preprocess, 305.1ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 5 trucks, 311.8ms\n",
      "Speed: 3.1ms preprocess, 311.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 4 trucks, 305.2ms\n",
      "Speed: 10.5ms preprocess, 305.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 375.2ms\n",
      "Speed: 3.0ms preprocess, 375.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 5 trucks, 321.7ms\n",
      "Speed: 4.8ms preprocess, 321.7ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 309.3ms\n",
      "Speed: 0.0ms preprocess, 309.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 329.6ms\n",
      "Speed: 0.0ms preprocess, 329.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 316.1ms\n",
      "Speed: 9.5ms preprocess, 316.1ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 320.3ms\n",
      "Speed: 0.0ms preprocess, 320.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 420.0ms\n",
      "Speed: 5.3ms preprocess, 420.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 4 trucks, 351.2ms\n",
      "Speed: 4.7ms preprocess, 351.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 389.9ms\n",
      "Speed: 15.8ms preprocess, 389.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 4 trucks, 388.2ms\n",
      "Speed: 4.4ms preprocess, 388.2ms inference, 5.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 343.4ms\n",
      "Speed: 6.5ms preprocess, 343.4ms inference, 15.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 349.6ms\n",
      "Speed: 6.3ms preprocess, 349.6ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 360.6ms\n",
      "Speed: 4.2ms preprocess, 360.6ms inference, 15.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 4 trucks, 372.7ms\n",
      "Speed: 1.0ms preprocess, 372.7ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 358.4ms\n",
      "Speed: 8.0ms preprocess, 358.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 385.5ms\n",
      "Speed: 0.9ms preprocess, 385.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 382.4ms\n",
      "Speed: 0.0ms preprocess, 382.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 359.9ms\n",
      "Speed: 5.6ms preprocess, 359.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 373.4ms\n",
      "Speed: 5.9ms preprocess, 373.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 309.2ms\n",
      "Speed: 8.1ms preprocess, 309.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 303.2ms\n",
      "Speed: 6.4ms preprocess, 303.2ms inference, 7.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 309.8ms\n",
      "Speed: 0.0ms preprocess, 309.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 318.0ms\n",
      "Speed: 2.9ms preprocess, 318.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 315.3ms\n",
      "Speed: 7.2ms preprocess, 315.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 318.8ms\n",
      "Speed: 8.0ms preprocess, 318.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 333.8ms\n",
      "Speed: 3.0ms preprocess, 333.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 321.4ms\n",
      "Speed: 0.0ms preprocess, 321.4ms inference, 6.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 348.5ms\n",
      "Speed: 2.4ms preprocess, 348.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 300.7ms\n",
      "Speed: 3.4ms preprocess, 300.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 316.4ms\n",
      "Speed: 4.3ms preprocess, 316.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 308.9ms\n",
      "Speed: 0.0ms preprocess, 308.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 326.0ms\n",
      "Speed: 13.5ms preprocess, 326.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 309.3ms\n",
      "Speed: 5.1ms preprocess, 309.3ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 324.1ms\n",
      "Speed: 0.0ms preprocess, 324.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 312.2ms\n",
      "Speed: 3.8ms preprocess, 312.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 299.8ms\n",
      "Speed: 0.0ms preprocess, 299.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 3 trucks, 328.3ms\n",
      "Speed: 3.0ms preprocess, 328.3ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 316.7ms\n",
      "Speed: 0.0ms preprocess, 316.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 317.2ms\n",
      "Speed: 8.5ms preprocess, 317.2ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 306.9ms\n",
      "Speed: 0.0ms preprocess, 306.9ms inference, 8.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 309.1ms\n",
      "Speed: 2.7ms preprocess, 309.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 317.3ms\n",
      "Speed: 15.6ms preprocess, 317.3ms inference, 6.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 287.6ms\n",
      "Speed: 12.5ms preprocess, 287.6ms inference, 13.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 309.8ms\n",
      "Speed: 3.6ms preprocess, 309.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 306.2ms\n",
      "Speed: 0.0ms preprocess, 306.2ms inference, 4.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 2 trucks, 322.9ms\n",
      "Speed: 0.5ms preprocess, 322.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 330.8ms\n",
      "Speed: 9.0ms preprocess, 330.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 8 cars, 2 trucks, 312.4ms\n",
      "Speed: 0.0ms preprocess, 312.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 8 cars, 2 trucks, 305.2ms\n",
      "Speed: 7.5ms preprocess, 305.2ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 7 cars, 2 trucks, 310.3ms\n",
      "Speed: 0.0ms preprocess, 310.3ms inference, 15.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 7 cars, 2 trucks, 311.0ms\n",
      "Speed: 3.1ms preprocess, 311.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 331.4ms\n",
      "Speed: 8.0ms preprocess, 331.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 2 trucks, 336.5ms\n",
      "Speed: 2.6ms preprocess, 336.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 2 trucks, 322.0ms\n",
      "Speed: 1.3ms preprocess, 322.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 308.1ms\n",
      "Speed: 0.0ms preprocess, 308.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 329.8ms\n",
      "Speed: 0.0ms preprocess, 329.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 3 trucks, 311.2ms\n",
      "Speed: 0.0ms preprocess, 311.2ms inference, 6.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 325.3ms\n",
      "Speed: 0.0ms preprocess, 325.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 9 cars, 3 trucks, 400.2ms\n",
      "Speed: 16.6ms preprocess, 400.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 330.3ms\n",
      "Speed: 4.3ms preprocess, 330.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 305.9ms\n",
      "Speed: 9.0ms preprocess, 305.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 325.2ms\n",
      "Speed: 0.0ms preprocess, 325.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 310.7ms\n",
      "Speed: 6.8ms preprocess, 310.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 324.7ms\n",
      "Speed: 3.4ms preprocess, 324.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 323.0ms\n",
      "Speed: 0.0ms preprocess, 323.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 389.1ms\n",
      "Speed: 4.9ms preprocess, 389.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 325.7ms\n",
      "Speed: 5.3ms preprocess, 325.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 335.4ms\n",
      "Speed: 0.0ms preprocess, 335.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 323.0ms\n",
      "Speed: 1.2ms preprocess, 323.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 323.8ms\n",
      "Speed: 0.0ms preprocess, 323.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 304.1ms\n",
      "Speed: 4.3ms preprocess, 304.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 314.5ms\n",
      "Speed: 0.0ms preprocess, 314.5ms inference, 14.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 353.2ms\n",
      "Speed: 4.1ms preprocess, 353.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 311.7ms\n",
      "Speed: 6.4ms preprocess, 311.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 1 bench, 320.2ms\n",
      "Speed: 0.0ms preprocess, 320.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 300.3ms\n",
      "Speed: 17.2ms preprocess, 300.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 306.9ms\n",
      "Speed: 1.5ms preprocess, 306.9ms inference, 4.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 326.4ms\n",
      "Speed: 2.0ms preprocess, 326.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 382.2ms\n",
      "Speed: 0.0ms preprocess, 382.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 320.9ms\n",
      "Speed: 0.0ms preprocess, 320.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 309.6ms\n",
      "Speed: 13.5ms preprocess, 309.6ms inference, 8.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 295.3ms\n",
      "Speed: 3.1ms preprocess, 295.3ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 311.6ms\n",
      "Speed: 2.1ms preprocess, 311.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 301.1ms\n",
      "Speed: 7.1ms preprocess, 301.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 321.3ms\n",
      "Speed: 0.7ms preprocess, 321.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 320.3ms\n",
      "Speed: 11.5ms preprocess, 320.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 316.4ms\n",
      "Speed: 2.9ms preprocess, 316.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 304.1ms\n",
      "Speed: 7.6ms preprocess, 304.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 308.3ms\n",
      "Speed: 0.8ms preprocess, 308.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 305.7ms\n",
      "Speed: 9.2ms preprocess, 305.7ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 313.2ms\n",
      "Speed: 5.4ms preprocess, 313.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 334.6ms\n",
      "Speed: 12.4ms preprocess, 334.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 360.4ms\n",
      "Speed: 6.4ms preprocess, 360.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 314.7ms\n",
      "Speed: 0.0ms preprocess, 314.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 324.2ms\n",
      "Speed: 1.0ms preprocess, 324.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 325.0ms\n",
      "Speed: 0.0ms preprocess, 325.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 311.7ms\n",
      "Speed: 0.0ms preprocess, 311.7ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 315.4ms\n",
      "Speed: 3.0ms preprocess, 315.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 317.8ms\n",
      "Speed: 15.9ms preprocess, 317.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 336.4ms\n",
      "Speed: 0.0ms preprocess, 336.4ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 320.2ms\n",
      "Speed: 3.0ms preprocess, 320.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 315.8ms\n",
      "Speed: 17.2ms preprocess, 315.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 310.8ms\n",
      "Speed: 0.0ms preprocess, 310.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 318.5ms\n",
      "Speed: 0.0ms preprocess, 318.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 313.3ms\n",
      "Speed: 0.0ms preprocess, 313.3ms inference, 10.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 310.0ms\n",
      "Speed: 6.7ms preprocess, 310.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 319.6ms\n",
      "Speed: 14.0ms preprocess, 319.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 303.1ms\n",
      "Speed: 2.6ms preprocess, 303.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 305.2ms\n",
      "Speed: 12.0ms preprocess, 305.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 312.9ms\n",
      "Speed: 3.6ms preprocess, 312.9ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 302.6ms\n",
      "Speed: 3.4ms preprocess, 302.6ms inference, 5.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 300.1ms\n",
      "Speed: 3.3ms preprocess, 300.1ms inference, 7.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 309.8ms\n",
      "Speed: 2.0ms preprocess, 309.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 3 trucks, 335.4ms\n",
      "Speed: 14.5ms preprocess, 335.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 299.2ms\n",
      "Speed: 0.0ms preprocess, 299.2ms inference, 11.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 5 trucks, 313.5ms\n",
      "Speed: 4.2ms preprocess, 313.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 4 trucks, 301.9ms\n",
      "Speed: 1.0ms preprocess, 301.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 4 trucks, 293.8ms\n",
      "Speed: 4.6ms preprocess, 293.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 4 trucks, 316.6ms\n",
      "Speed: 8.0ms preprocess, 316.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 5 trucks, 312.6ms\n",
      "Speed: 0.0ms preprocess, 312.6ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 3 trucks, 352.1ms\n",
      "Speed: 2.8ms preprocess, 352.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 297.0ms\n",
      "Speed: 4.1ms preprocess, 297.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 310.4ms\n",
      "Speed: 6.1ms preprocess, 310.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 313.9ms\n",
      "Speed: 0.0ms preprocess, 313.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 319.2ms\n",
      "Speed: 0.0ms preprocess, 319.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 315.8ms\n",
      "Speed: 6.2ms preprocess, 315.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 321.2ms\n",
      "Speed: 0.0ms preprocess, 321.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 299.0ms\n",
      "Speed: 2.4ms preprocess, 299.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 315.9ms\n",
      "Speed: 0.0ms preprocess, 315.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 311.6ms\n",
      "Speed: 0.0ms preprocess, 311.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 314.3ms\n",
      "Speed: 0.0ms preprocess, 314.3ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 333.9ms\n",
      "Speed: 0.0ms preprocess, 333.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 327.0ms\n",
      "Speed: 0.0ms preprocess, 327.0ms inference, 13.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 2 trucks, 311.0ms\n",
      "Speed: 0.0ms preprocess, 311.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 4 trucks, 340.5ms\n",
      "Speed: 6.1ms preprocess, 340.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 295.5ms\n",
      "Speed: 2.8ms preprocess, 295.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 325.2ms\n",
      "Speed: 6.8ms preprocess, 325.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 311.4ms\n",
      "Speed: 3.0ms preprocess, 311.4ms inference, 15.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 323.6ms\n",
      "Speed: 0.0ms preprocess, 323.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 359.6ms\n",
      "Speed: 3.2ms preprocess, 359.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 395.8ms\n",
      "Speed: 0.0ms preprocess, 395.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 374.3ms\n",
      "Speed: 0.0ms preprocess, 374.3ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 321.7ms\n",
      "Speed: 6.0ms preprocess, 321.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 4 trucks, 319.0ms\n",
      "Speed: 0.0ms preprocess, 319.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 324.2ms\n",
      "Speed: 8.5ms preprocess, 324.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 336.4ms\n",
      "Speed: 4.7ms preprocess, 336.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 317.0ms\n",
      "Speed: 0.0ms preprocess, 317.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 304.5ms\n",
      "Speed: 9.5ms preprocess, 304.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 311.7ms\n",
      "Speed: 0.0ms preprocess, 311.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 5 trucks, 299.4ms\n",
      "Speed: 6.5ms preprocess, 299.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 4 trucks, 316.6ms\n",
      "Speed: 17.4ms preprocess, 316.6ms inference, 15.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 315.1ms\n",
      "Speed: 1.6ms preprocess, 315.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 341.2ms\n",
      "Speed: 4.5ms preprocess, 341.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 316.3ms\n",
      "Speed: 9.9ms preprocess, 316.3ms inference, 16.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 3 trucks, 309.8ms\n",
      "Speed: 5.5ms preprocess, 309.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 3 trucks, 309.1ms\n",
      "Speed: 0.0ms preprocess, 309.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 329.3ms\n",
      "Speed: 5.0ms preprocess, 329.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 3 trucks, 306.8ms\n",
      "Speed: 0.0ms preprocess, 306.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 2 trucks, 333.6ms\n",
      "Speed: 1.5ms preprocess, 333.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 3 trucks, 363.5ms\n",
      "Speed: 0.0ms preprocess, 363.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 366.1ms\n",
      "Speed: 7.1ms preprocess, 366.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 349.2ms\n",
      "Speed: 0.0ms preprocess, 349.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 350.6ms\n",
      "Speed: 0.0ms preprocess, 350.6ms inference, 12.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 2 trucks, 351.5ms\n",
      "Speed: 9.8ms preprocess, 351.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 5 trucks, 421.2ms\n",
      "Speed: 4.1ms preprocess, 421.2ms inference, 8.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 354.7ms\n",
      "Speed: 10.7ms preprocess, 354.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 333.0ms\n",
      "Speed: 0.0ms preprocess, 333.0ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 414.7ms\n",
      "Speed: 0.0ms preprocess, 414.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 319.5ms\n",
      "Speed: 7.3ms preprocess, 319.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 335.7ms\n",
      "Speed: 1.5ms preprocess, 335.7ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 379.1ms\n",
      "Speed: 0.0ms preprocess, 379.1ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 338.3ms\n",
      "Speed: 3.5ms preprocess, 338.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 4 trucks, 382.0ms\n",
      "Speed: 5.5ms preprocess, 382.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 13 cars, 5 trucks, 389.7ms\n",
      "Speed: 5.6ms preprocess, 389.7ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 361.0ms\n",
      "Speed: 0.0ms preprocess, 361.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 408.1ms\n",
      "Speed: 8.0ms preprocess, 408.1ms inference, 5.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 420.6ms\n",
      "Speed: 8.9ms preprocess, 420.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 340.5ms\n",
      "Speed: 3.5ms preprocess, 340.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 2 trucks, 379.0ms\n",
      "Speed: 4.5ms preprocess, 379.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 cars, 3 trucks, 304.4ms\n",
      "Speed: 10.0ms preprocess, 304.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 cars, 3 trucks, 374.9ms\n",
      "Speed: 9.0ms preprocess, 374.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 cars, 3 trucks, 406.9ms\n",
      "Speed: 15.7ms preprocess, 406.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 16 cars, 4 trucks, 450.8ms\n",
      "Speed: 2.8ms preprocess, 450.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 4 trucks, 370.6ms\n",
      "Speed: 0.0ms preprocess, 370.6ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 5 trucks, 406.9ms\n",
      "Speed: 1.5ms preprocess, 406.9ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 4 trucks, 346.0ms\n",
      "Speed: 8.1ms preprocess, 346.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 4 trucks, 415.5ms\n",
      "Speed: 0.0ms preprocess, 415.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 3 trucks, 372.4ms\n",
      "Speed: 0.0ms preprocess, 372.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 3 trucks, 344.7ms\n",
      "Speed: 2.7ms preprocess, 344.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 360.3ms\n",
      "Speed: 15.6ms preprocess, 360.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 4 trucks, 458.3ms\n",
      "Speed: 7.8ms preprocess, 458.3ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 4 trucks, 379.7ms\n",
      "Speed: 1.0ms preprocess, 379.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 350.4ms\n",
      "Speed: 2.1ms preprocess, 350.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 2 trucks, 317.0ms\n",
      "Speed: 0.0ms preprocess, 317.0ms inference, 13.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 5 trucks, 355.6ms\n",
      "Speed: 4.1ms preprocess, 355.6ms inference, 5.3ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 3 trucks, 350.8ms\n",
      "Speed: 3.8ms preprocess, 350.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 384.6ms\n",
      "Speed: 4.7ms preprocess, 384.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 349.2ms\n",
      "Speed: 2.5ms preprocess, 349.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 3 trucks, 349.7ms\n",
      "Speed: 0.0ms preprocess, 349.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 380.3ms\n",
      "Speed: 0.0ms preprocess, 380.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 414.6ms\n",
      "Speed: 0.0ms preprocess, 414.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 2 trucks, 367.4ms\n",
      "Speed: 4.6ms preprocess, 367.4ms inference, 14.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 387.8ms\n",
      "Speed: 6.1ms preprocess, 387.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 359.5ms\n",
      "Speed: 7.0ms preprocess, 359.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 347.4ms\n",
      "Speed: 0.0ms preprocess, 347.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 335.4ms\n",
      "Speed: 0.0ms preprocess, 335.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 415.9ms\n",
      "Speed: 0.0ms preprocess, 415.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 383.2ms\n",
      "Speed: 8.1ms preprocess, 383.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 353.0ms\n",
      "Speed: 2.0ms preprocess, 353.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 343.6ms\n",
      "Speed: 9.0ms preprocess, 343.6ms inference, 6.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 360.7ms\n",
      "Speed: 5.9ms preprocess, 360.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 332.5ms\n",
      "Speed: 14.0ms preprocess, 332.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 367.9ms\n",
      "Speed: 8.0ms preprocess, 367.9ms inference, 14.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 336.7ms\n",
      "Speed: 4.1ms preprocess, 336.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 331.8ms\n",
      "Speed: 2.5ms preprocess, 331.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 331.5ms\n",
      "Speed: 4.3ms preprocess, 331.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 338.9ms\n",
      "Speed: 4.2ms preprocess, 338.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 325.1ms\n",
      "Speed: 9.5ms preprocess, 325.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 15 cars, 2 trucks, 392.2ms\n",
      "Speed: 0.0ms preprocess, 392.2ms inference, 12.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 381.4ms\n",
      "Speed: 2.5ms preprocess, 381.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 1 truck, 367.4ms\n",
      "Speed: 3.4ms preprocess, 367.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 319.2ms\n",
      "Speed: 13.5ms preprocess, 319.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 324.7ms\n",
      "Speed: 0.0ms preprocess, 324.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 332.1ms\n",
      "Speed: 0.0ms preprocess, 332.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 391.3ms\n",
      "Speed: 4.6ms preprocess, 391.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 363.3ms\n",
      "Speed: 3.3ms preprocess, 363.3ms inference, 5.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 1 truck, 352.2ms\n",
      "Speed: 13.0ms preprocess, 352.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 1 person, 10 cars, 1 truck, 353.4ms\n",
      "Speed: 8.0ms preprocess, 353.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 318.7ms\n",
      "Speed: 0.0ms preprocess, 318.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 319.9ms\n",
      "Speed: 11.5ms preprocess, 319.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 2 trucks, 374.1ms\n",
      "Speed: 3.8ms preprocess, 374.1ms inference, 7.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 392.7ms\n",
      "Speed: 0.0ms preprocess, 392.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 10 cars, 1 truck, 345.5ms\n",
      "Speed: 10.3ms preprocess, 345.5ms inference, 16.5ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 9 cars, 2 trucks, 403.6ms\n",
      "Speed: 6.1ms preprocess, 403.6ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 11 cars, 1 truck, 413.8ms\n",
      "Speed: 5.2ms preprocess, 413.8ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 13 cars, 424.6ms\n",
      "Speed: 0.0ms preprocess, 424.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 433.5ms\n",
      "Speed: 0.0ms preprocess, 433.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 391.5ms\n",
      "Speed: 0.0ms preprocess, 391.5ms inference, 3.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 379.9ms\n",
      "Speed: 3.4ms preprocess, 379.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 14 cars, 413.0ms\n",
      "Speed: 14.5ms preprocess, 413.0ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 12 cars, 2 trucks, 373.3ms\n",
      "Speed: 3.1ms preprocess, 373.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m    count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m    frame\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(frame,(\u001b[38;5;241m1020\u001b[39m,\u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m    results\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#   print(results)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m    a\u001b[38;5;241m=\u001b[39mresults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:444\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:456\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 456\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 141\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    239\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:396\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MANASA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2101\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "   \n",
    "\n",
    "    results=model.predict(frame)\n",
    " #   print(results)\n",
    "    a=results[0].boxes.data\n",
    "    a = a.detach().cpu().numpy() \n",
    "    px=pd.DataFrame(a).astype(\"float\")\n",
    "    #print(px)\n",
    "\n",
    "    list=[]\n",
    "             \n",
    "    for index,row in px.iterrows():\n",
    "#        print(row) \n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        if 'car' in c:\n",
    "            list.append([x1,y1,x2,y2])\n",
    "            #print(c)\n",
    "\n",
    "    bbox_id=tracker.update(list)\n",
    "    #print(bbox_id)\n",
    "    for bbox in bbox_id:\n",
    "        x3,y3,x4,y4,id=bbox\n",
    "        cx=int(x3+x4)//2\n",
    "        cy=int(y3+y4)//2\n",
    "        cv2.circle(frame,(cx,cy),4,(0,0,255),-1) #draw ceter points of bounding box\n",
    "        cv2.rectangle(frame, (x3, y3), (x4, y4), (0, 255, 0), 2)  # Draw bounding box\n",
    "        cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "\n",
    "\n",
    "        red_line_y=198\n",
    "        blue_line_y=268   \n",
    "        offset = 7\n",
    "        \n",
    "  \n",
    "        if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "          down[id]=cy   \n",
    "        if id in down:\n",
    "           if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):         \n",
    "             cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "             cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "             #counter+=1\n",
    "             counter_down.append(id)  \n",
    "\n",
    "        # condition for cars entering from  blue line\n",
    "        if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "          up[id]=cy   \n",
    "        if id in up:\n",
    "           if red_line_y < (cy + offset) and red_line_y > (cy - offset):         \n",
    "             cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "             cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "            \n",
    "             counter_up.append(id) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    text_color = (255,255,255) \n",
    "    red_color = (0, 0, 255)  # (B, G, R)   \n",
    "    blue_color = (255, 0, 0)  # (B, G, R)\n",
    "    green_color = (0, 255, 0)  # (B, G, R)  \n",
    "\n",
    "    cv2.line(frame,(172,198),(774,198),red_color,3)  \n",
    "    cv2.putText(frame,('red line'),(172,198),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.line(frame,(8,268),(927,268),blue_color,3)  \n",
    "    cv2.putText(frame,('blue line'),(8,268),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)    \n",
    "\n",
    "\n",
    "    downwards = (len(counter_down))\n",
    "    cv2.putText(frame,('going down - ')+ str(downwards),(60,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, green_color, 1, cv2.LINE_AA)    \n",
    "\n",
    "    \n",
    "    upwards = (len(counter_up))\n",
    "    cv2.putText(frame,('going up - ')+ str(upwards),(60,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)  \n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bde883-a7d0-4b8c-ba8e-d90ae0dd4dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db098f-c7c1-44b7-979a-7a34f4e66b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
